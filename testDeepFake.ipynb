{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9604080,
          "sourceType": "datasetVersion",
          "datasetId": 5859560
        },
        {
          "sourceId": 9604085,
          "sourceType": "datasetVersion",
          "datasetId": 5859565
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import v2\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "MmlzJY9kdAVb",
        "execution": {
          "iopub.status.busy": "2024-10-13T15:27:51.456772Z",
          "iopub.execute_input": "2024-10-13T15:27:51.457467Z",
          "iopub.status.idle": "2024-10-13T15:27:57.453291Z",
          "shell.execute_reply.started": "2024-10-13T15:27:51.457422Z",
          "shell.execute_reply": "2024-10-13T15:27:57.452269Z"
        },
        "trusted": true
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepfakeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepfakeNet, self).__init__()\n",
        "#         self.drp = nn.Dropout(0.4)#------------------------------------------------------------------------------------------------------------------------\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layers = nn.ModuleList([Bottleneck(64, 256, first=True)])\n",
        "        self.out_size = [256,512,1024,2048]\n",
        "        self.blocks = [1,2,2,1]\n",
        "        for i in range(len(self.out_size)):\n",
        "            if i > 0:\n",
        "                self.layers.append(Bottleneck(self.out_size[i-1], self.out_size[i], 2))\n",
        "            for extraLayers in range(self.blocks[i]-1):\n",
        "                self.layers.append(Bottleneck(self.out_size[i], self.out_size[i]))\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(2048, 1)\n",
        "\n",
        "\n",
        "\n",
        "    # def _make_layer(self, in_channels, out_channels, blocks):\n",
        "    #     layers = []\n",
        "    #     for _ in range(blocks):\n",
        "    #         layers.append(Bottleneck(in_channels, out_channels))\n",
        "    #     return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "#         x = self.drp(x)#------------------------------------------------------------------------------------------------------------------------------------\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2vE2v6ecexpm",
        "execution": {
          "iopub.status.busy": "2024-10-13T15:29:38.598081Z",
          "iopub.execute_input": "2024-10-13T15:29:38.598401Z",
          "iopub.status.idle": "2024-10-13T15:29:38.609219Z",
          "shell.execute_reply.started": "2024-10-13T15:29:38.598368Z",
          "shell.execute_reply": "2024-10-13T15:29:38.608188Z"
        },
        "trusted": true
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, first=False):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        mid_channels = out_channels//2\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=mid_channels, kernel_size=1)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
        "        self.conv2 = nn.Conv2d(in_channels=mid_channels, out_channels=mid_channels, kernel_size=3, padding=1, groups=32, stride=stride)\n",
        "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
        "        self.conv3 = nn.Conv2d(in_channels=mid_channels, out_channels=out_channels, kernel_size=1)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.downsample = stride == 2 or first\n",
        "        if self.downsample:\n",
        "            self.changeInputC2D = nn.Conv2d(in_channels = in_channels, out_channels=out_channels, kernel_size=1, stride=stride)\n",
        "            self.changeInputBn = nn.BatchNorm2d(out_channels)\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample:\n",
        "            residual = self.changeInputC2D(residual)\n",
        "            residual = self.changeInputBn(residual)\n",
        "        out = torch.add(out, residual)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "UYx2xmBqe303",
        "execution": {
          "iopub.status.busy": "2024-10-13T15:29:38.610359Z",
          "iopub.execute_input": "2024-10-13T15:29:38.610646Z",
          "iopub.status.idle": "2024-10-13T15:29:38.624326Z",
          "shell.execute_reply.started": "2024-10-13T15:29:38.610614Z",
          "shell.execute_reply": "2024-10-13T15:29:38.623034Z"
        },
        "trusted": true
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Calculate average loss\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    training_loss.append(avg_loss)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "3fPC-PqQfAc9",
        "execution": {
          "iopub.status.busy": "2024-10-13T15:29:38.625458Z",
          "iopub.execute_input": "2024-10-13T15:29:38.625808Z",
          "iopub.status.idle": "2024-10-13T15:29:38.638141Z",
          "shell.execute_reply.started": "2024-10-13T15:29:38.625774Z",
          "shell.execute_reply": "2024-10-13T15:29:38.637307Z"
        },
        "trusted": true
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Accumulate loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predicted = torch.round(outputs)\n",
        "            # print(outputs)\n",
        "            # print(predicted)\n",
        "            # print(labels)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate average loss and accuracy\n",
        "    avg_loss = val_loss / len(dataloader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    validation_loss.append(avg_loss)\n",
        "    validation_acc.append(accuracy)\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "9kspkkkofGdy",
        "execution": {
          "iopub.status.busy": "2024-10-13T15:29:38.639400Z",
          "iopub.execute_input": "2024-10-13T15:29:38.639742Z",
          "iopub.status.idle": "2024-10-13T15:29:38.652365Z",
          "shell.execute_reply.started": "2024-10-13T15:29:38.639700Z",
          "shell.execute_reply": "2024-10-13T15:29:38.651464Z"
        },
        "trusted": true
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "iYvdWLkvfVCo",
        "execution": {
          "iopub.status.busy": "2024-10-13T15:29:38.653556Z",
          "iopub.execute_input": "2024-10-13T15:29:38.654183Z",
          "iopub.status.idle": "2024-10-13T15:29:38.938299Z",
          "shell.execute_reply.started": "2024-10-13T15:29:38.654141Z",
          "shell.execute_reply": "2024-10-13T15:29:38.937277Z"
        },
        "trusted": true
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel = torch.load(\"___path_to_weights____\", weights_only=False)\n",
        "newModel.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at0lauK06hkX",
        "outputId": "0d5f8d16-1bbb-46a4-a48f-3123bdef1624"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepfakeNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layers): ModuleList(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (changeInputC2D): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (changeInputBn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (changeInputC2D): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "      (changeInputBn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (changeInputC2D): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
              "      (changeInputBn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (changeInputC2D): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
              "      (changeInputBn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "newModel.eval()\n",
        "path = \"/content/deepfake/DF and Real/DF/WhatsApp Image 2024-09-02 at 7.35.24 PM.jpeg\"\n",
        "img = Image.open(path)\n",
        "img\n",
        "basic = v2.Compose([v2.Resize((224,224)),v2.ToTensor()])\n",
        "img = basic(img)\n",
        "\n",
        "img = img.to(device)\n",
        "img = img.view((1,3,224,224))\n",
        "if torch.round(newModel(img)).item()==1:\n",
        "  print(\"FAKE\")\n",
        "else:\n",
        "  print(\"REAL\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjjFWCDf5T-9",
        "outputId": "3282bddf-fc1f-4ec2-b9e9-97f08e028436"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAKE\n"
          ]
        }
      ]
    }
  ]
}